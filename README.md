# PrivaTranslate

ローカル翻訳システムです。プライバシーやセキュリティが心配な文章を翻訳するときに使うと便利かもしれません。また、Google翻訳やDeepLなどが使えなくなった場合（インターネットが使えない場合など）にも役立ちます。

Macbook Pro M4上でGemma3:4bモデルを使用してテスト済みです。Macbook上でありながら、実用的なスピードで翻訳が可能です。より高速に動作させたい場合は、より小さなモデルを使用するか、GPU搭載のPCでOllamaを動作させるとよいです。

## 特徴

- ローカル環境で動作するため、プライバシーが保護されます（Ollama cloudを使うと、データが外部に送信される可能性があります）。
- インターネット接続がなくても（モデルダウンロードをしてあれば）動作します。
- Google翻訳などの外部APIに依存しません。
- システムプロンプトを工夫すれば、翻訳後の文章やトーンなどのフォーマットを調整できます。
- LaTeXの数式を含む文章もある程度翻訳可能なように、プロンプトを工夫したり、MathJaxを使えるようにしています。

## 注意

- 本プログラムコードは、ほぼVibe codingで作成しています。
- LaTeXの数式を処理できるようシステムプロンプトを工夫していますが、完全ではありません。モデルのパラメタによっては、数式があると翻訳しなくなる場合があります。

## 必要な環境

- Python 3.7以上
- Ollama（ローカルLLMサーバー）
  - Macの場合は、Ollamaアプリをインストールすれば使えます。
  - OLLAMA_API_URLは現在バックエンド(app.py)が実行されるマシン上で動作しているOllamaサーバーを使用するように設定されていますが、設定を変えれば、ローカルネットワークにある別のマシン上のOllamaサーバーを使用することも可能です。

## インストール方法

### 1. 必要なPythonライブラリのインストール

```bash
pip install -r requirements.txt
```

または、個別にインストールする場合：

```bash
pip install Flask flask-cors requests
```

### 2. Ollamaのインストールと設定

1. [Ollama](https://ollama.ai/)をインストール
2. 翻訳用のモデルをダウンロード：
   ```bash
   ollama pull gemma3:4b
   ```

## 使い方

1. Ollamaサーバーが起動していることを確認
2. Flaskアプリケーションを起動：
   ```bash
   python app.py
   ```
3. ブラウザで `index.html` を開く
4. テキストを入力して翻訳


